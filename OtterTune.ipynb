{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VM867AA9yPU7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.decomposition import FactorAnalysis, PCA, KernelPCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, Normalizer, StandardScaler, MaxAbsScaler, KBinsDiscretizer\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, RationalQuadratic, Matern, DotProduct, WhiteKernel, ConstantKernel\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataRepo:\n",
    "    '''\n",
    "    Data repository. Contains methods to prune metrics and preprocess knobs.\n",
    "    '''\n",
    "    def __init__(self, params, verbose=True, offline_path='./data/train/offline_workload.csv'):\n",
    "        self.OFFLINE_WL_PATH = offline_path\n",
    "        self.METRICS_START_IDX = 14\n",
    "        self.LATENCY_IDX = 13\n",
    "        self.INT_KNOBS_IDXS = [9, 10, 11, 12]\n",
    "        self.CONT_KNOBS_IDXS = [1, 2, 3, 4, 5, 6, 8]\n",
    "        self.BOOL_KNOS_IDX = 7\n",
    "        self.pruned_metrics_idxs = None\n",
    "        self.pruned_metrics_names = None\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.dim_reducer = None\n",
    "        self.kmeans = None\n",
    "        self.int_encoder = None\n",
    "        self.cont_encoder = None\n",
    "        self.latency_scaler = None\n",
    "        self.metric_scaler = None\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.__set_hyperparams(params)\n",
    "        \n",
    "    def __set_hyperparams(self, params):\n",
    "        self.dim_reducer = params['dim_reducer']\n",
    "        self.kmeans = params['kmeans']\n",
    "        self.int_encoder = params['int_encoder']\n",
    "        self.cont_encoder = params['cont_encoder']\n",
    "        if params['latency_scaler']:\n",
    "            self.latency_scaler = clone(params['latency_scaler'])\n",
    "        if params['metric_scaler']:\n",
    "            self.metric_scaler = clone(params['metric_scaler'])\n",
    "    \n",
    "    def _build(self):\n",
    "        '''\n",
    "        Run only once by OtterTune object.\n",
    "        Prunes metrics and preprocesses knobs in offline workloads.\n",
    "        Final processed data is not saved, rather returned to \n",
    "        OtterTune to create Workload objects.\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            print('Pruning metrics and pre-processing knobs...')\n",
    "        pruned_data = self.__prune_offline_metrics(self.OFFLINE_WL_PATH)\n",
    "        \n",
    "        latency_idx = self.LATENCY_IDX\n",
    "        metrics_idx = self.METRICS_START_IDX\n",
    "        \n",
    "        if self.latency_scaler:\n",
    "            pruned_data.iloc[:, latency_idx] = self.latency_scaler.fit_transform(pruned_data.iloc[:, latency_idx].to_numpy().reshape(-1, 1))\n",
    "        \n",
    "        if self.metric_scaler:\n",
    "            pruned_data.iloc[:, metrics_idx:] = self.metric_scaler.fit_transform(pruned_data.iloc[:, metrics_idx:])\n",
    "        \n",
    "        processed_data = self.__preprocess_workload_knobs(pruned_data)\n",
    "        return processed_data\n",
    "    \n",
    "    def process_online_workload(self, raw_workload):\n",
    "        '''\n",
    "        Prune metrics and preprocess knobs of online workloads.\n",
    "        '''\n",
    "        latency_idx = self.LATENCY_IDX\n",
    "        metrics_idx = self.METRICS_START_IDX\n",
    "        \n",
    "        pruned_data = self.__prune_online_metrics(raw_workload)\n",
    "        \n",
    "        if self.latency_scaler:\n",
    "            pruned_data.iloc[:, latency_idx] = self.latency_scaler.transform(pruned_data.iloc[:, latency_idx].to_numpy().reshape(-1, 1))\n",
    "        \n",
    "        if self.metric_scaler:\n",
    "            pruned_data.iloc[:, metrics_idx:] = self.metric_scaler.transform(pruned_data.iloc[:, metrics_idx:])\n",
    "            \n",
    "        return self.__preprocess_workload_knobs(pruned_data, online=True)\n",
    "    \n",
    "    def process_test_knobs(self, test_knobs):\n",
    "        '''\n",
    "        Preprocess test knobs.\n",
    "        '''\n",
    "        return self.__preprocess_workload_knobs(test_knobs, online=True, only_knobs=True)\n",
    "          \n",
    "    def __prune_offline_metrics(self, file_path):\n",
    "        '''\n",
    "        Prune offline workloads metrics using FA + KMeans.\n",
    "        NOTE: Modularize to use any technique.\n",
    "        '''\n",
    "        data = pd.read_csv(file_path)\n",
    "        metrics = data.to_numpy()[:, self.METRICS_START_IDX:].T\n",
    "\n",
    "        metric_factors = self.dim_reducer.fit_transform(metrics)\n",
    "        kmeans = self.kmeans.fit(metric_factors)\n",
    "        closest_idxs, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, metric_factors)\n",
    "        self.pruned_metrics_idxs = closest_idxs\n",
    "        closest_idxs_raw = [self.METRICS_START_IDX + idx for idx in closest_idxs]\n",
    "        self.pruned_metrics_names = data.columns[closest_idxs_raw].tolist()\n",
    "        \n",
    "        pruned_metrics = metrics[self.pruned_metrics_idxs].T\n",
    "        n_cols = data.shape[1]\n",
    "        metric_cols = np.linspace(self.METRICS_START_IDX, n_cols - 1, n_cols - self.METRICS_START_IDX, dtype=int)\n",
    "        data.drop(data.columns[metric_cols], axis=1, inplace=True)\n",
    "        pruned_data = pd.concat([data, pd.DataFrame(pruned_metrics)], axis=1)\n",
    "        return pruned_data\n",
    "        \n",
    "    def __prune_online_metrics(self, raw_workload):\n",
    "        '''\n",
    "        Prune online workloads metrics using identified\n",
    "        non-redundant metrics from offline workloads.\n",
    "        '''\n",
    "        data = raw_workload.reset_index(drop=True)\n",
    "        metrics = data.to_numpy()[:, self.METRICS_START_IDX:].T\n",
    "        pruned_metrics = metrics[self.pruned_metrics_idxs].T\n",
    "        \n",
    "        n_cols = data.shape[1]\n",
    "        metric_cols = np.linspace(self.METRICS_START_IDX, n_cols - 1, n_cols - self.METRICS_START_IDX, dtype=int)\n",
    "        data.drop(data.columns[metric_cols], axis=1, inplace=True)\n",
    "        pruned_data = pd.concat([data, pd.DataFrame(pruned_metrics)], axis=1)\n",
    "        return pruned_data\n",
    "    \n",
    "    def __preprocess_workload_knobs(self, pruned_data, online=False, only_knobs=False):\n",
    "        '''\n",
    "        Preprocess knobs.\n",
    "        If online is True, transform using fitted encoders (online knobs)\n",
    "        Otherwise, fit and then transform (offline knobs)\n",
    "        For test knobs, only_knobs is True.\n",
    "        '''\n",
    "        col_names = pruned_data.columns.tolist()\n",
    "        pruned_n = pruned_data.to_numpy()\n",
    "        int_knobs = self.INT_KNOBS_IDXS\n",
    "        cont_knobs = self.CONT_KNOBS_IDXS\n",
    "        bool_knob = self.BOOL_KNOS_IDX\n",
    "        \n",
    "        if only_knobs:\n",
    "            int_knobs = [idx - 1 for idx in int_knobs]\n",
    "            cont_knobs = [idx - 1 for idx in cont_knobs]\n",
    "            bool_knob = bool_knob - 1\n",
    "            online = True\n",
    "        \n",
    "        if not online:\n",
    "            if self.int_encoder:\n",
    "                pruned_n[:, int_knobs] = self.int_encoder.fit_transform(pruned_n[:, int_knobs])\n",
    "            if self.cont_encoder:\n",
    "                pruned_n[:, cont_knobs] = self.cont_encoder.fit_transform(pruned_n[:, cont_knobs])\n",
    "        else:\n",
    "            if self.int_encoder:\n",
    "                pruned_n[:, int_knobs] = self.int_encoder.transform(pruned_n[:, int_knobs])\n",
    "            if self.cont_encoder:\n",
    "                pruned_n[:, cont_knobs] = self.cont_encoder.transform(pruned_n[:, cont_knobs])\n",
    "        \n",
    "        pruned_n[:, bool_knob] = pruned_n[:, bool_knob].astype(int)\n",
    "        return pd.DataFrame(pruned_n, columns=col_names)\n",
    "    \n",
    "    def _inverse_latency(self, latency):\n",
    "        return self.latency_scaler.inverse_transform(latency.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OtterTune:\n",
    "    '''\n",
    "    Main OtterTune system. Contains methods to perform workload mapping and predicting latency.\n",
    "    '''\n",
    "    def __init__(self, repo, params, verbose=True):\n",
    "        self.repo = repo\n",
    "        self.metric_model = None\n",
    "        self.metric_binner = None\n",
    "        self.N_METRICS = None\n",
    "        \n",
    "        self.workloads = []\n",
    "        self.verbose = verbose\n",
    "        self.__set_hyperparams(params)\n",
    "        self.__build_workloads()\n",
    "        \n",
    "    def __set_hyperparams(self, params):\n",
    "        self.metric_model = params['metric_model']\n",
    "        self.metric_binner = params['metric_binner']\n",
    "        \n",
    "    def __build_workloads(self):\n",
    "        '''\n",
    "        Run only once at OtterTune object creation.\n",
    "        Creates Workload objects and build metric models on each.\n",
    "        '''\n",
    "        data = self.repo._build()        \n",
    "        latency_idx = self.repo.LATENCY_IDX\n",
    "        wl_ids = data['workload id'].unique()\n",
    "        \n",
    "        for wl_id in tqdm(wl_ids, desc='Building Offline Workloads', disable=not self.verbose):\n",
    "            wl_data = data[data['workload id'] == wl_id].to_numpy()\n",
    "            knobs = wl_data[:, 1:latency_idx]\n",
    "            metrics = wl_data[:, latency_idx:]\n",
    "            if not self.N_METRICS:\n",
    "                self.N_METRICS = metrics.shape[1]\n",
    "            workload = Workload(wl_id, knobs, metrics, self.metric_model)\n",
    "            workload.build_metric_models()\n",
    "            self.workloads.append(workload)    \n",
    "    \n",
    "    def predict(self, raw_workload, test_knobs, wl_idx=None):\n",
    "        '''\n",
    "        Predicts latency for test knobs given online workload.\n",
    "        Uses helper functions for workload mapping and to\n",
    "        augment online workload with matched offline workload.\n",
    "        '''\n",
    "        processed_wl = self.repo.process_online_workload(raw_workload)\n",
    "        processed_wl_metrics = processed_wl.iloc[:, 13:]\n",
    "        processed_wl_knobs = processed_wl.iloc[:, 1:13]\n",
    "        processed_test_knobs = self.repo.process_test_knobs(test_knobs)\n",
    "    \n",
    "        best_wl_idx = wl_idx\n",
    "        if not wl_idx:\n",
    "            best_wl_idx = self.__get_best_workload(processed_wl_knobs, processed_wl_metrics)\n",
    "        aug_wl = self.__get_augmented_workload(best_wl_idx, processed_wl)\n",
    "        \n",
    "        gpr = clone(self.metric_model)\n",
    "        gpr.fit(aug_wl[:, :-1], aug_wl[:, -1])\n",
    "        pred = gpr.predict(processed_test_knobs)\n",
    "        \n",
    "        if self.repo.latency_scaler:\n",
    "            pred = self.repo._inverse_latency(pred).reshape(-1)\n",
    "        return pred[0], self.workloads[best_wl_idx].wl_id\n",
    "    \n",
    "    def __get_augmented_workload(self, best_wl_idx, processed_wl):\n",
    "        '''\n",
    "        Given matched workload, augment current online workload data.\n",
    "        '''\n",
    "        w = self.workloads[best_wl_idx]\n",
    "        w_knobs, w_latency = w.knobs, w.metrics[:, 0].reshape(-1, 1)\n",
    "        offline = np.concatenate((w_knobs, w_latency), 1)\n",
    "        \n",
    "        online = processed_wl.iloc[:, 1:14].to_numpy()\n",
    "        aug_wl = np.concatenate((offline, online), 0)\n",
    "        return aug_wl\n",
    "        \n",
    "    def __get_best_workload(self, wl_knobs, wl_metrics):\n",
    "        '''\n",
    "        Performs workload mapping given online workload (knobs, metrics).\n",
    "        '''\n",
    "        n_wls, n_configs = len(self.workloads), len(wl_knobs)\n",
    "        S = self.__build_distance_matrix(wl_knobs)\n",
    "        \n",
    "        binned_S, transf = self.__bin_metrics(S)\n",
    "        online_metrics = self.__bin_online_metrics(wl_metrics, transf)\n",
    "        \n",
    "        best_wl_idx = np.argmin(np.mean(np.sqrt(np.sum((binned_S - online_metrics)**2, axis=2)), axis=0))\n",
    "        return best_wl_idx\n",
    "    \n",
    "    def __build_distance_matrix(self, train_knobs):\n",
    "        '''\n",
    "        Build distance matrix S (paper section 6.1).\n",
    "        Helps efficiently calculate closest offline workload.\n",
    "        '''\n",
    "        n_wls, n_configs = len(self.workloads), len(train_knobs)\n",
    "        S = np.zeros((self.N_METRICS, n_wls, n_configs))\n",
    "        for metric_idx in range(self.N_METRICS):\n",
    "            for wl_idx, w in enumerate(self.workloads):\n",
    "                row = w.predict_metric(metric_idx, train_knobs)\n",
    "                S[metric_idx, wl_idx, :] = row\n",
    "        return S\n",
    "\n",
    "    def __bin_metrics(self, S):\n",
    "        '''\n",
    "        Normalizes metrics with bin number using deciles.\n",
    "        Needed to perform accurate distance comparisons.\n",
    "        '''\n",
    "        n_metrics, n_wls, n_configs = S.shape\n",
    "        sr = S.reshape(n_wls*n_configs, n_metrics)\n",
    "        metric_binner = clone(self.metric_binner)\n",
    "        sr = metric_binner.fit_transform(sr)\n",
    "        S = sr.reshape(n_metrics, n_wls, n_configs)\n",
    "        return S, metric_binner\n",
    "        \n",
    "    def __bin_online_metrics(self, wl_metrics, metric_binner):\n",
    "        '''\n",
    "        Normalizes online metrics with bin number using deciles.\n",
    "        Uses previsouly used encoder (transf).\n",
    "        '''\n",
    "        online_metrics = metric_binner.transform(wl_metrics).T\n",
    "        online_metrics = np.repeat(online_metrics[:, np.newaxis, :], len(self.workloads), axis=1)\n",
    "        return online_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Workload:\n",
    "    '''\n",
    "    Models each workload. Contains methods to train GPR models on each metric.\n",
    "    Predicts latency (metric index 0).\n",
    "    '''\n",
    "    def __init__(self, wl_id, knobs, metrics, metric_model):\n",
    "        self.wl_id = wl_id\n",
    "        self.knobs = knobs\n",
    "        self.metrics = metrics\n",
    "        self.metric_model = metric_model\n",
    "        self.models = {}\n",
    "        self.N_METRICS = metrics.shape[1]\n",
    "        \n",
    "    def build_metric_models(self):\n",
    "        '''\n",
    "        Train GPR models on each metric.\n",
    "        '''\n",
    "        for metric_idx in range(self.N_METRICS):\n",
    "            model = clone(self.metric_model)\n",
    "            model.fit(self.knobs, self.metrics[:, metric_idx])\n",
    "            self.models[metric_idx] = model\n",
    "        \n",
    "    def predict_metric(self, metric_idx, knobs):\n",
    "        '''\n",
    "        Predict a metric using existing model.\n",
    "        '''\n",
    "        return self.models[metric_idx].predict(knobs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester:\n",
    "    '''\n",
    "    Driver class to run val/test workloads and report performance.\n",
    "    Each workload required 3 files.\n",
    "    online_path - Online workloads file\n",
    "    test_path - Test Knobs file\n",
    "    true_path - True Latency for test knobs file\n",
    "    '''\n",
    "    def __init__(self, ottertune, mode='val', verbose=True, save_results=True, perf='mape'):\n",
    "        self.mode = mode # either 'val' or 'test'\n",
    "        self.ONLINE_PATH = None # online workload\n",
    "        self.TEST_PATH = None # test knobs (like test.csv)\n",
    "        self.TRUE_PATH = None # true latency (only for 'val')\n",
    "        self.RESULT_PATH = None # To write out results\n",
    "        \n",
    "        self.o = ottertune\n",
    "        self.online_workloads = {}\n",
    "        self.test_knobs = {}\n",
    "        self.true_preds = None\n",
    "        self.wl_ids = None\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        self.save_results = save_results\n",
    "        self.perf = perf\n",
    "        \n",
    "        self.__set_file_paths()\n",
    "        self.__load_data()\n",
    "        \n",
    "    def __set_file_paths(self):\n",
    "        '''\n",
    "        Sets file paths based on val/test dataset.\n",
    "        '''\n",
    "        path = './data/' + self.mode + '/'\n",
    "        self.ONLINE_PATH = path + 'online_workload.csv' \n",
    "        self.TEST_PATH = path + 'test_knobs.csv' \n",
    "        \n",
    "        # Not a CSV as the MSE is added to file name later\n",
    "        self.RESULT_PATH = './data/out/' + self.mode + '_results'\n",
    "        if self.mode == 'val' or self.mode == 'sanity':\n",
    "            self.TRUE_PATH = path + 'true_latency.csv'\n",
    "        \n",
    "    def __load_data(self):\n",
    "        '''\n",
    "        Run only once at creation of Tester.\n",
    "        Loads all 3 required files.\n",
    "        '''\n",
    "        online = pd.read_csv(self.ONLINE_PATH)\n",
    "        knobs = pd.read_csv(self.TEST_PATH)\n",
    "        if self.mode == 'val' or self.mode == 'sanity':\n",
    "            self.true_preds = pd.read_csv(self.TRUE_PATH, header=None).to_numpy().reshape(-1)\n",
    "        wl_ids = online['workload id'].unique().tolist()\n",
    "        self.wl_ids = wl_ids\n",
    "        for wl_id in tqdm(wl_ids, desc='Loading Online Workloads', disable=not self.verbose):\n",
    "            w = online[online['workload id'] == wl_id]\n",
    "            k = knobs[knobs['workload id'] == wl_id].iloc[:, 1:]\n",
    "            self.online_workloads[wl_id] = w\n",
    "            self.test_knobs[wl_id] = k\n",
    "            \n",
    "    def mean_absolute_percentage_error(self, y_true, y_pred): \n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "                \n",
    "    def run(self):\n",
    "        '''\n",
    "        Runs each workload to predict latency for each test knob.\n",
    "        Saves result file with true/pred workload id and latency.\n",
    "        Prints MSE across all workloads.\n",
    "        '''\n",
    "        preds_arr = []\n",
    "        pi = 0\n",
    "        for wl_id in tqdm(self.wl_ids, desc='Running Target Workloads', disable=not self.verbose):\n",
    "            online_wl = self.online_workloads[wl_id]\n",
    "            test_knobs = self.test_knobs[wl_id]\n",
    "            pred, best_wl_id = self.o.predict(online_wl, test_knobs)\n",
    "            if self.mode == 'val' or self.mode == 'sanity':\n",
    "                preds_arr.append([wl_id, best_wl_id, self.true_preds[pi], pred])\n",
    "            elif self.mode == 'test':\n",
    "                preds_arr.append([wl_id, best_wl_id, pred])                    \n",
    "            pi += 1\n",
    "        \n",
    "        if self.mode == 'val' or self.mode == 'sanity':\n",
    "            column_names = ['wl_id', 'mapped_wl_id', 'true_latency', 'latency_pred']\n",
    "            df = pd.DataFrame(preds_arr, columns=column_names)                \n",
    "            perf_num = self.mean_absolute_percentage_error(self.true_preds, df.iloc[:, -1].to_numpy())\n",
    "            if self.perf == 'mae':\n",
    "                perf_num = mean_absolute_error(self.true_preds, df.iloc[:, -1].to_numpy())\n",
    "            if self.save_results:\n",
    "                df.to_csv(self.RESULT_PATH + '_(' + str(round(perf_num, 2)) + ').csv')\n",
    "            return perf_num\n",
    "        elif self.mode == 'test':\n",
    "            if self.save_results:\n",
    "                column_names = ['wl_id', 'mapped_wl_id', 'latency_pred']\n",
    "                df = pd.DataFrame(preds_arr, columns=column_names)\n",
    "                df.to_csv(self.RESULT_PATH + '.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "\n",
    "#### DataRepo\n",
    "* Load offline workloads, prune metrics, pre-process knobs.\n",
    "* Saves pruned metrics, knob encoders to be used later to transform online workloads.\n",
    "\n",
    "#### OtterTune \n",
    "* Create offline Workload objects from processed offline data from DataRepo  \n",
    "* Given online workload and test knobs, performs workload mapping\n",
    "* Augments current workload with mapped workload\n",
    "* Predict latency for test knobs  \n",
    "* Uses pruned metric info and trained knob encoders in DataRepo to transform online workloads\n",
    "\n",
    "#### Workload\n",
    "* Models a single workload\n",
    "* Contains GPR models trained on each metric (knobs -> GPR -> latency/metric)\n",
    "\n",
    "#### Tester\n",
    "* Works given a mode ('val' or 'test')\n",
    "* Loads online workloads and their respective test knobs\n",
    "* If 'val', loads true latencies to report mean absolute error (MAE)\n",
    "* Saves a result file under `./data/out/` with mapped workload info and predicted latency\n",
    "* Result file name `val_results_({MAE}).csv`\n",
    "\n",
    "#### Datasets\n",
    "* Train - offline_workload.csv (makes our DataRepo)\n",
    "* Val – online_workload_B.csv (100 workloads with 6 configs each) split into 3 files\n",
    "    1. `online_workload.csv` (100 workloads with 5 configs each, randomly chosen)\n",
    "    2. `test_knobs.csv` (100 workloads with left out 1 config each)\n",
    "    3. `true_latency.csv` (True latency values for each test knob in test_knobs.csv)\n",
    "* Test – online_workload_C.csv and provided test knobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = ConstantKernel(1.0, (1e-1, 1e3)) * RBF(3.0, (1e-2, 1e2))\n",
    "params = {\n",
    "    'dim_reducer': KernelPCA(n_components=2, kernel='poly', degree=5),\n",
    "    'kmeans': KMeans(n_clusters=8),\n",
    "    'int_encoder': OrdinalEncoder(),\n",
    "    'cont_encoder': MinMaxScaler(),\n",
    "    'metric_model': DecisionTreeRegressor(),\n",
    "    'metric_binner': KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile'),\n",
    "    'latency_scaler': MinMaxScaler(),\n",
    "    'metric_scaler': MinMaxScaler()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "repo = DataRepo(params)\n",
    "o = OtterTune(repo, params)\n",
    "t = Tester(o, mode='val')\n",
    "t.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tuner:\n",
    "    def __init__(self, param_grid, mode, out = './data/out/tuning_results.csv'):\n",
    "        self.param_grid_list = list(ParameterGrid(param_grid))\n",
    "        self.mode = mode\n",
    "        self.out= out\n",
    "        print('Loaded', len(self.param_grid_list), 'parameter combinations.')\n",
    "    \n",
    "    def tune(self):\n",
    "        mape_df = []\n",
    "        \n",
    "        if self.mode == 'sanity':\n",
    "            desc = 'Tuning params on sanity'\n",
    "            path = './data/sanity/offline_workload.csv'\n",
    "            \n",
    "        if self.mode == 'val':\n",
    "            desc = 'Tuning params on val'\n",
    "            path = './data/train/offline_workload.csv'\n",
    "        \n",
    "        for params in tqdm(self.param_grid_list, desc= desc):\n",
    "            params['kmeans'] = KMeans(n_clusters=params['n_clusters'])\n",
    "            repo = DataRepo(params, offline_path= path, verbose=False)\n",
    "            o = OtterTune(repo, params, verbose=False)\n",
    "            t = Tester(o, mode=self.mode, verbose=False, save_results=False)\n",
    "            mape = t.run(save=False)\n",
    "            mape_df.append(mape)\n",
    "     \n",
    "        df = pd.DataFrame(self.param_grid_list)\n",
    "        df['mape'] = mape_df\n",
    "        df.to_csv(self.out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore convergence warnings etc. during tuning \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create parameter search grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 304 parameter combinations.\n"
     ]
    }
   ],
   "source": [
    "kernel = DotProduct() + WhiteKernel()\n",
    "param_grid = {\n",
    "    'dim_reducer': [PCA(n_components=2), KernelPCA(n_components=2, kernel='poly')],\n",
    "    'n_clusters': list(range(2, 21)),\n",
    "    'int_encoder': [None, OrdinalEncoder()],\n",
    "    'cont_encoder': [None, MinMaxScaler()],\n",
    "    'metric_model': [GaussianProcessRegressor(kernel=kernel), DecisionTreeRegressor()],\n",
    "    'metric_binner': [KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')],\n",
    "    'latency_scaler': [MinMaxScaler()],\n",
    "    'metric_scaler': [MinMaxScaler()]\n",
    "}\n",
    "\n",
    "tuner = Tuner(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tuning params on val:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Tuning params on val:  50%|█████     | 1/2 [03:10<03:10, 190.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "Tuning params on val: 100%|██████████| 2/2 [06:35<00:00, 197.99s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "tuner.tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "OtterTune.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
