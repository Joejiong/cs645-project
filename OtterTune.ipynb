{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VM867AA9yPU7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.decomposition import FactorAnalysis, PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, KBinsDiscretizer\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(offline_path, save_path='./data/split_data/'):\n",
    "    '''\n",
    "    Splits original offline workload into train and val sets\n",
    "    Random configs of each workload are split into train (offline) and val (online)\n",
    "    Random configs of val are further split into val and test (just the knobs).\n",
    "    NOTE: Messy, will clean up later\n",
    "    '''\n",
    "    offline = pd.read_csv(offline_path)\n",
    "    X, y = offline, offline['latency']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=645)\n",
    "    X_train.sort_values('workload id').to_csv(save_path + 'offline_workload.csv', index=False)\n",
    "    XT_train, XT_test, yT_train, yT_test = train_test_split(X_test, y_test, test_size=0.30, random_state=645)\n",
    "    XT_train.sort_values('workload id').to_csv(save_path + 'online_workload.csv', index=False)\n",
    "    XT_test.iloc[:, :13].sort_values('workload id').to_csv(save_path + 'test_knobs.csv', index=False)\n",
    "    XT_test.iloc[:, [0,13]].sort_values('workload id').iloc[:, 1].to_csv(save_path + 'true_latency.csv', index=False, header=False)\n",
    "    \n",
    "    # Of the 58 workloads, how many are represented in test workloads\n",
    "    # Making sure we test at least one config in each workload\n",
    "    print(XT_train['workload id'].nunique(), XT_test['workload id'].nunique())\n",
    "    \n",
    "# Only run once, will directly load after\n",
    "# split_train_val('./data/orig/offline_workload.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataRepo:\n",
    "    '''\n",
    "    Data repository. Contains methods to prune metrics and preprocess knobs.\n",
    "    '''\n",
    "    def __init__(self, offline_path, n_factors=2, n_clusters=5, int_enc=OrdinalEncoder(), cont_enc=MinMaxScaler()):\n",
    "        self.OFFLINE_WL_PATH = offline_path\n",
    "        self.METRICS_START_IDX = 14\n",
    "        self.LATENCY_IDX = 13\n",
    "        self.INT_KNOBS_IDXS = [9, 10, 11, 12]\n",
    "        self.CONT_KNOBS_IDXS = [1, 2, 3, 4, 5, 6, 8]\n",
    "        self.BOOL_KNOS_IDX = 7\n",
    "        \n",
    "        self.N_FACTORS = n_factors # no. of factors for Factor Analysis\n",
    "        self.N_CLUSTERS = n_clusters # k in KMeans\n",
    "        \n",
    "        self.pruned_metrics_idxs = None\n",
    "        self.pruned_metrics_names = None\n",
    "        self.int_encoder = int_enc # Encoder for integer knobs\n",
    "        self.cont_encoder = cont_enc # Encoder for continuous knobs\n",
    "    \n",
    "    def _build(self):\n",
    "        '''\n",
    "        Run only once at the beginning of DataRepo creation.\n",
    "        Prunes metrics and preprocesses knobs in offline workloads.\n",
    "        Final processed data is not saved, rather returned to \n",
    "        OtterTune to create Workload objects.\n",
    "        '''\n",
    "        pruned_data = self.__prune_offline_metrics(self.OFFLINE_WL_PATH)\n",
    "        processed_data = self.__preprocess_workload_knobs(pruned_data)\n",
    "        return processed_data\n",
    "    \n",
    "    def process_online_workload(self, raw_workload):\n",
    "        '''\n",
    "        Prune metrics and preprocess knobs of online workloads.\n",
    "        '''\n",
    "        pruned_data = self.__prune_online_metrics(raw_workload)\n",
    "        return self.__preprocess_workload_knobs(pruned_data, online=True)\n",
    "    \n",
    "    def process_test_knobs(self, test_knobs):\n",
    "        '''\n",
    "        Preprocess test knobs.\n",
    "        '''\n",
    "        return self.__preprocess_workload_knobs(test_knobs, online=True, only_knobs=True)\n",
    "          \n",
    "    def __prune_offline_metrics(self, file_path=None):\n",
    "        '''\n",
    "        Prune offline workloads metrics using FA + KMeans.\n",
    "        NOTE: Modularize to use any technique.\n",
    "        '''\n",
    "        data = pd.read_csv(file_path)\n",
    "        metrics = data.to_numpy()[:, self.METRICS_START_IDX:].T\n",
    "\n",
    "        fa = FactorAnalysis(n_components=self.N_FACTORS)\n",
    "        metric_factors = fa.fit_transform(metrics)\n",
    "        km = KMeans(n_clusters=self.N_CLUSTERS).fit(metric_factors)\n",
    "        closest_idxs, _ = pairwise_distances_argmin_min(km.cluster_centers_, metric_factors)\n",
    "        self.pruned_metrics_idxs = closest_idxs\n",
    "        closest_idxs_raw = [self.METRICS_START_IDX + idx for idx in closest_idxs]\n",
    "        self.pruned_metrics_names = data.columns[closest_idxs_raw].tolist()\n",
    "        \n",
    "        pruned_metrics = metrics[self.pruned_metrics_idxs].T\n",
    "        n_cols = data.shape[1]\n",
    "        metric_cols = np.linspace(self.METRICS_START_IDX, n_cols - 1, n_cols - self.METRICS_START_IDX, dtype=int)\n",
    "        data.drop(data.columns[metric_cols], axis=1, inplace=True)\n",
    "        pruned_data = pd.concat([data, pd.DataFrame(pruned_metrics)], axis=1)\n",
    "        return pruned_data\n",
    "        \n",
    "    def __prune_online_metrics(self, raw_workload):\n",
    "        '''\n",
    "        Prune online workloads metrics using identified\n",
    "        non-redundant metrics from offline workloads.\n",
    "        '''\n",
    "        data = raw_workload.reset_index(drop=True)\n",
    "        metrics = data.to_numpy()[:, self.METRICS_START_IDX:].T\n",
    "        pruned_metrics = metrics[self.pruned_metrics_idxs].T\n",
    "        \n",
    "        n_cols = data.shape[1]\n",
    "        metric_cols = np.linspace(self.METRICS_START_IDX, n_cols - 1, n_cols - self.METRICS_START_IDX, dtype=int)\n",
    "        data.drop(data.columns[metric_cols], axis=1, inplace=True)\n",
    "        pruned_data = pd.concat([data, pd.DataFrame(pruned_metrics)], axis=1)\n",
    "        return pruned_data\n",
    "    \n",
    "    def __preprocess_workload_knobs(self, pruned_data, online=False, only_knobs=False):\n",
    "        '''\n",
    "        Preprocess knobs.\n",
    "        If online is True, transform using fitted encoders (online knobs)\n",
    "        Otherwise, fit and then transform (offline knobs)\n",
    "        For test knobs, only_knobs is True.\n",
    "        '''\n",
    "        col_names = pruned_data.columns.tolist()\n",
    "        pruned_n = pruned_data.to_numpy()\n",
    "        int_knobs = self.INT_KNOBS_IDXS\n",
    "        cont_knobs = self.CONT_KNOBS_IDXS\n",
    "        bool_knob = self.BOOL_KNOS_IDX\n",
    "        \n",
    "        if only_knobs:\n",
    "            int_knobs = [idx - 1 for idx in int_knobs]\n",
    "            cont_knobs = [idx - 1 for idx in cont_knobs]\n",
    "            bool_knob = bool_knob - 1\n",
    "            online = True\n",
    "        \n",
    "        \n",
    "        if not online:\n",
    "            pruned_n[:, int_knobs] = self.int_encoder.fit_transform(pruned_n[:, int_knobs])\n",
    "            pruned_n[:, cont_knobs] = self.cont_encoder.fit_transform(pruned_n[:, cont_knobs])\n",
    "        else:\n",
    "            pruned_n[:, int_knobs] = self.int_encoder.transform(pruned_n[:, int_knobs])\n",
    "            pruned_n[:, cont_knobs] = self.cont_encoder.transform(pruned_n[:, cont_knobs])\n",
    "        \n",
    "        pruned_n[:, bool_knob] = pruned_n[:, bool_knob].astype(int)\n",
    "        return pd.DataFrame(pruned_n, columns=col_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OtterTune:\n",
    "    '''\n",
    "    Main OtterTune system. Contains methods to perform workload mapping and predicting latency.\n",
    "    '''\n",
    "    def __init__(self, repo, metric_model=GaussianProcessRegressor(kernel=RBF(length_scale=1.0))):\n",
    "        self.repo = repo\n",
    "        self.metric_model = metric_model # Used to model each metric in each workload\n",
    "        self.N_METRICS = None\n",
    "        \n",
    "        self.workloads = []        \n",
    "        self.__build_workloads()\n",
    "        \n",
    "        \n",
    "    def __build_workloads(self):\n",
    "        '''\n",
    "        Run only once at OtterTune object creation.\n",
    "        Creates Workload objects and build metric models on each.\n",
    "        '''\n",
    "        print('Building data repository...')\n",
    "        data = self.repo._build()        \n",
    "        latency_idx = self.repo.LATENCY_IDX\n",
    "        wl_ids = data['workload id'].unique()\n",
    "        \n",
    "        for wl_id in tqdm(wl_ids, desc='Building Offline Workloads'):\n",
    "            wl_data = data[data['workload id'] == wl_id].to_numpy()\n",
    "            knobs = wl_data[:, 1:latency_idx]\n",
    "            metrics = wl_data[:, latency_idx:]\n",
    "            if not self.N_METRICS:\n",
    "                self.N_METRICS = metrics.shape[1]\n",
    "            workload = Workload(wl_id, knobs, metrics, self.metric_model)\n",
    "            workload.build_metric_models()\n",
    "            self.workloads.append(workload)    \n",
    "    \n",
    "    def predict(self, raw_workload, test_knobs):\n",
    "        '''\n",
    "        Predicts latency for test knobs given online workload.\n",
    "        Uses helper functions for workload mapping and to\n",
    "        augment online workload with matched offline workload.\n",
    "        '''\n",
    "        processed_wl = self.repo.process_online_workload(raw_workload)\n",
    "        processed_wl_metrics = processed_wl.iloc[:, 13:]\n",
    "        processed_wl_knobs = processed_wl.iloc[:, 1:13]\n",
    "        processed_test_knobs = self.repo.process_test_knobs(test_knobs)\n",
    "\n",
    "        best_wl_idx = self.__get_best_workload(processed_wl_knobs, processed_wl_metrics)\n",
    "        aug_wl = self.__get_augmented_workload(best_wl_idx, processed_wl)\n",
    "        \n",
    "        gpr = GaussianProcessRegressor(kernel=RBF(length_scale=1.0))\n",
    "        gpr.fit(aug_wl[:, :-1], aug_wl[:, -1])\n",
    "        preds = gpr.predict(processed_test_knobs)\n",
    "        return preds, self.workloads[best_wl_idx].wl_id\n",
    "    \n",
    "    def __get_augmented_workload(self, best_wl_idx, processed_wl):\n",
    "        '''\n",
    "        Given matched workload, augment current online workload data.\n",
    "        '''\n",
    "        w = self.workloads[best_wl_idx]\n",
    "        w_knobs, w_latency = w.knobs, w.metrics[:, 0].reshape(-1, 1)\n",
    "        offline = np.concatenate((w_knobs, w_latency), 1)\n",
    "        \n",
    "        online = processed_wl.iloc[:, 1:14].to_numpy()\n",
    "        aug_wl = np.concatenate((offline, online), 0)\n",
    "        return aug_wl\n",
    "        \n",
    "    def __get_best_workload(self, wl_knobs, wl_metrics):\n",
    "        '''\n",
    "        Performs workload mapping given online workload (knobs, metrics).\n",
    "        '''\n",
    "        n_wls, n_configs = len(self.workloads), len(wl_knobs)\n",
    "        S = self.__build_distance_matrix(wl_knobs)\n",
    "        \n",
    "        binned_S, transf = self.__bin_metrics(S)\n",
    "        online_metrics = self.__bin_online_metrics(wl_metrics, transf)\n",
    "        \n",
    "        best_wl_idx = np.argmin(np.mean(np.sqrt(np.sum((binned_S - online_metrics)**2, axis=2)), axis=0))\n",
    "        return best_wl_idx\n",
    "    \n",
    "    def __build_distance_matrix(self, train_knobs):\n",
    "        '''\n",
    "        Build distance matrix S (paper section 6.1).\n",
    "        Helps efficiently calculate closest offline workload.\n",
    "        '''\n",
    "        n_wls, n_configs = len(self.workloads), len(train_knobs)\n",
    "        S = np.zeros((self.N_METRICS, n_wls, n_configs))\n",
    "        for metric_idx in range(self.N_METRICS):\n",
    "            for wl_idx, w in enumerate(self.workloads):\n",
    "                row = w.predict_metric(metric_idx, train_knobs)\n",
    "                S[metric_idx, wl_idx, :] = row\n",
    "        return S\n",
    "\n",
    "    def __bin_metrics(self, S):\n",
    "        '''\n",
    "        Normalizes metrics with bin number using deciles.\n",
    "        Needed to perform accurate distance comparisons.\n",
    "        '''\n",
    "        n_metrics, n_wls, n_configs = S.shape\n",
    "        sr = S.reshape(n_wls*n_configs, n_metrics)\n",
    "        transf = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "        sr = transf.fit_transform(sr)\n",
    "        S = sr.reshape(n_metrics, n_wls, n_configs)\n",
    "        return S, transf\n",
    "        \n",
    "    def __bin_online_metrics(self, wl_metrics, transf):\n",
    "        '''\n",
    "        Normalizes online metrics with bin number using deciles.\n",
    "        Uses previsouly used encoder (transf).\n",
    "        '''\n",
    "        online_metrics = transf.transform(wl_metrics).T\n",
    "        online_metrics = np.repeat(online_metrics[:, np.newaxis, :], len(self.workloads), axis=1)\n",
    "        return online_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Workload:\n",
    "    '''\n",
    "    Models each workload. Contains methods to train GPR models on each metric.\n",
    "    Predicts latency (metric index 0).\n",
    "    '''\n",
    "    def __init__(self, wl_id, knobs, metrics, metric_model):\n",
    "        self.wl_id = wl_id\n",
    "        self.knobs = knobs\n",
    "        self.metrics = metrics\n",
    "        self.metric_model = metric_model\n",
    "        self.models = {}\n",
    "        self.N_METRICS = metrics.shape[1]\n",
    "        \n",
    "    def build_metric_models(self):\n",
    "        '''\n",
    "        Train GPR models on each metric.\n",
    "        '''\n",
    "        for metric_idx in range(self.N_METRICS):\n",
    "            model = clone(self.metric_model)\n",
    "            model.fit(self.knobs, self.metrics[:, metric_idx])\n",
    "            self.models[metric_idx] = model\n",
    "        \n",
    "    def predict_metric(self, metric_idx, knobs):\n",
    "        '''\n",
    "        Predict a metric using existing model.\n",
    "        '''\n",
    "        return self.models[metric_idx].predict(knobs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester:\n",
    "    '''\n",
    "    Driver class to run val/test workloads and report performance.\n",
    "    Each workload required 3 files.\n",
    "    online_path - Online workloads file\n",
    "    test_path - Test Knobs file\n",
    "    true_path - True Latency for test knobs file\n",
    "    '''\n",
    "    def __init__(self, ottertune, online_path, test_path, true_path):\n",
    "        self.ONLINE_PATH = online_path\n",
    "        self.TEST_PATH = test_path\n",
    "        self.TRUE_PATH = true_path\n",
    "        self.o = ottertune\n",
    "        \n",
    "        self.online_workloads = {}\n",
    "        self.test_knobs = {}\n",
    "        self.true_preds = None\n",
    "        self.wl_ids = None\n",
    "        self.__load_data()\n",
    "        \n",
    "    def __load_data(self):\n",
    "        '''\n",
    "        Run only once at creation of Tester.\n",
    "        Loads all 3 required files.\n",
    "        '''\n",
    "        online = pd.read_csv(self.ONLINE_PATH)\n",
    "        knobs = pd.read_csv(self.TEST_PATH)\n",
    "        self.true_preds = pd.read_csv(self.TRUE_PATH, header=None).to_numpy().reshape(-1)\n",
    "        wl_ids = online['workload id'].unique().tolist()\n",
    "        self.wl_ids = wl_ids\n",
    "        for wl_id in tqdm(wl_ids, desc='Loading Online Workloads'):\n",
    "            w = online[online['workload id'] == wl_id]\n",
    "            k = knobs[knobs['workload id'] == wl_id].iloc[:, 1:]\n",
    "            self.online_workloads[wl_id] = w\n",
    "            self.test_knobs[wl_id] = k\n",
    "                \n",
    "    def run(self, out_file):\n",
    "        '''\n",
    "        Runs each workload to predict latency for each test knob.\n",
    "        Saves result file with true/pred workload id and latency.\n",
    "        Prints MSE across all workloads.\n",
    "        '''\n",
    "        preds_arr = []\n",
    "        pi = 0\n",
    "        for wl_id in tqdm(self.wl_ids, desc='Running Target Workloads'):\n",
    "            online_wl = self.online_workloads[wl_id]\n",
    "            test_knobs = self.test_knobs[wl_id]\n",
    "            preds, best_wl_id = self.o.predict(online_wl, test_knobs)\n",
    "            for p in preds: \n",
    "                preds_arr.append([wl_id, best_wl_id, self.true_preds[pi], p])\n",
    "                pi += 1\n",
    "        \n",
    "        df = pd.DataFrame(preds_arr, columns=['true_wl_id', 'pred_wl_id', 'true_latency', 'latency_pred'])\n",
    "        df.to_csv(out_file)\n",
    "        print('MSE:', mean_squared_error(self.true_preds, df.iloc[:, -1].to_numpy()))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing a sample workloads (./data/sample/)\n",
    "Offline Workloads - first 3 workloads from original offline workloads  \n",
    "Online Workloads - 5 random configs of only 1 workload (the first one)  \n",
    "Test Knobs - 2 random configs to predict latency on  \n",
    "True Latency - True latency of test knobs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'sample' # one of ['sample', 'split_data']\n",
    "path = './data/' + dataset + '/'\n",
    "out_file = './data/out/' + dataset + '_results.csv' # To write out test results\n",
    "offline_path = path + 'offline_workload.csv' # offline workload\n",
    "online_path = path + 'online_workload.csv' # online workload\n",
    "test_path = path + 'test_knobs.csv' # test knobs (like test.csv)\n",
    "true_path = path + 'true_latency.csv' # true latency (to measure performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataRepo, OtterTune, Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building data repository...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Offline Workloads: 100%|██████████| 3/3 [00:00<00:00,  6.73it/s]\n",
      "Loading Online Workloads: 100%|██████████| 1/1 [00:00<00:00, 310.09it/s]\n"
     ]
    }
   ],
   "source": [
    "repo = DataRepo(offline_path)\n",
    "o = OtterTune(repo)\n",
    "t = Tester(o, online_path, test_path, true_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict test knobs and report MSE\n",
    "Very small MSE as test knobs are also present in offline set.  \n",
    "Easy workload mapping for the same reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Target Workloads: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.8649540383401883e-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t.run(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing original workloads (./data/split_data/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'split_data' # one of ['sample', 'split_data']\n",
    "path = './data/' + dataset + '/'\n",
    "out_file = './data/out/' + dataset + '_results.csv' # To write out test results\n",
    "offline_path = path + 'offline_workload.csv' # offline workload\n",
    "online_path = path + 'online_workload.csv' # online workload\n",
    "test_path = path + 'test_knobs.csv' # test knobs (like test.csv)\n",
    "true_path = path + 'true_latency.csv' # true latency (to measure performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataRepo, OtterTune, Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building data repository...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Offline Workloads: 100%|██████████| 58/58 [00:06<00:00,  9.25it/s]\n",
      "Loading Online Workloads: 100%|██████████| 58/58 [00:00<00:00, 401.03it/s]\n"
     ]
    }
   ],
   "source": [
    "repo = DataRepo(offline_path)\n",
    "o = OtterTune(repo)\n",
    "t = Tester(o, online_path, test_path, true_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict test knobs and report MSE\n",
    "Huge MSE.  \n",
    "\"results.csv\" (./data/out/) from the run shows lots of incorrect workload mapping and value \"0\" predictions for latency. Could be due to a combination of hyperparams within pruning metrics, choice of normalization of various knobs, GPR kernels etc.  \n",
    "NOTE: Will push update after making sure its only because of hyperparams and not a programming issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Target Workloads:  21%|██        | 12/58 [00:04<00:15,  3.06it/s]/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:159: UserWarning: Feature 4 is constant and will be replaced with 0.\n",
      "  \"replaced with 0.\" % jj)\n",
      "Running Target Workloads:  41%|████▏     | 24/58 [00:07<00:10,  3.18it/s]/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:159: UserWarning: Feature 1 is constant and will be replaced with 0.\n",
      "  \"replaced with 0.\" % jj)\n",
      "Running Target Workloads:  53%|█████▎    | 31/58 [00:10<00:09,  2.98it/s]/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/_discretization.py:159: UserWarning: Feature 4 is constant and will be replaced with 0.\n",
      "  \"replaced with 0.\" % jj)\n",
      "Running Target Workloads: 100%|██████████| 58/58 [00:19<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 14808.391568475066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t.run(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "OtterTune.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
